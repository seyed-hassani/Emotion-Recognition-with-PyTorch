{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nz6b0pjfbT9X"
      },
      "source": [
        "<h1 dir=rtl align=center style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "احساسات با پایتورچ\n",
        "</font>\n",
        "</h1>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\">\n",
        "در این مسئله قصد داریم مدلی آموزش دهیم که بتواند با مشاهده‌ی تصویری از صورت یک شخص، احساس وی (عصبانیت، خوشحالی، ترس و غیره) را تشخیص دهد.\n",
        "به این بهانه می‌توانیم یک‌بار به‌صورت کامل نحوه‌ی ساخت و آموزش یک شبکه‌ی عصبی با فریم‌ورک پای‌تورچ را تمرین کنیم. علاوه‌براین با نحوه‌ی استفاده از یک مدل پیش‌آموخته در پای‌تورچ و <i>fine-tune</i> کردن وزن‌های آن جهت تطبیق مدل با مجموعه‌داده‌ی خودمان آشنا خواهیم شد.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\">\n",
        "<span style=\"color:green\"><b>یادآوری:</b></span>\n",
        "منظور از ‌<i>fine-tune</i> کردن مدل این است که ابتدا از وزن‌های پیش‌آموخته به‌عنوان وزن‌های اولیه‌ی مدل استفاده کنیم، اما به کل مدل یا تعدادی از لایه‌های آن اجازه دهیم که وزن‌هایش طبق نمونه‌های مسئله‌ی خودمان دوباره آموزش داده شود. در این‌صورت جهت دست‌یابی به مدلی با عملکرد مناسب، نیاز به نمونه‌های کمتری داریم و فرآیند آموزش مدل نیز سریع‌تر خواهد شد (نیاز به آموزش وزن‌های بسیار زیادی وجود ندارد). جهت یادآوری بیشتر می‌توانید به درسنامه‌ی «انتقال یادگیری» از فصل شبکه‌های عصبی کانولوشنی مراجعه کنید.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFiHBvZAbFrF"
      },
      "source": [
        "<h2 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "مجموعه‌داده\n",
        "</font>\n",
        "</h2>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\">\n",
        "مجموعه‌داده‌ی این تمرین شامل تعدادی عکس سیاه‌و‌سفید از صورت یک فرد است و قصد داریم مدلی آموزش دهیم که از روی صورت فرد، احساس وی را درک کند. احساسات مورد بررسی شامل «عصبانیت»، «ترس»، «ناراحتی»، «خوشحالی»، «انزجار»، «تعجب» و «بدون حس خاصی» است.\n",
        "<br>\n",
        "برای آن‌که مجموعه‌داده حجم کمتری داشته باشد، از فرمت <code>parquet</code> استفاده شده است. برای خوانش این نوع فایل در پانداز می‌توانید از تابع <code>read_parquet</code> کمک بگیرید. جهت مطالعه‌ی مستندات این تابع می‌توانید به این <a href=\"https://pandas.pydata.org/pandas-docs/version/1.5/reference/api/pandas.read_parquet.html\">لینک</a> مراجعه کنید.\n",
        "\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\">\n",
        "<span style=\"color:orange\"><b>نکته:</b></span>\n",
        "حجم فایل آموزشی و آزمون به‌ترتیب حدود ۶۸ و ۸ مگابایت است. در صورتی‌که بارگذاری این فایل‌ها در محیط کولب برای‌تان دشوار است می‌توانید با استفاده از دستورهای زیر این دو فایل را به‌صورت مستقیم در محیط کولب بارگیری کنید.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "`!gdown 10X11GsRgxToT9y4OjXJPXr_ilRygykZz`\n",
        "\n",
        "`!gdown 1vpuIWrZlSqGsvCILWMpYJG35YGFnBnhg`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Getting the data from the google drive\n",
        "# !gdown 10X11GsRgxToT9y4OjXJPXr_ilRygykZz\n",
        "# !gdown 1vpuIWrZlSqGsvCILWMpYJG35YGFnBnhg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0W5VM81hehkI"
      },
      "outputs": [],
      "source": [
        "df_train_eval = None # TODO\n",
        "df_test =  None # TODO\n",
        "df_train_eval.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA-iCaLIfeBK"
      },
      "source": [
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\">\n",
        "متغیر <code>train_eval</code> را به دو بخش <code>train</code> که شامل <code>0.9</code> نمونه‌ها و <code>eval</code> که شامل <code>0.1</code> داده‌هاست تقسیم می‌کنیم. برای این کار می‌توانید از تابع <code>train_test_split</code>  استفاده کنید.\n",
        "توجه کنید که با توجه به هم خوردن نمایه‌ها (<code>index</code>) نیاز است پس از این عملیات تابع <code>df.reset_index(drop=True)</code> را بر روی تمامی دیتافریم‌ها اعمال کنید.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2024-02-27T12:05:22.993669Z",
          "iopub.status.busy": "2024-02-27T12:05:22.993372Z",
          "iopub.status.idle": "2024-02-27T12:05:25.678200Z",
          "shell.execute_reply": "2024-02-27T12:05:25.677434Z",
          "shell.execute_reply.started": "2024-02-27T12:05:22.993638Z"
        },
        "id": "FZcBHe5ObFrH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_train, df_eval = None # TODO\n",
        "\n",
        "\n",
        "df_train = None # TODO: reset the index\n",
        "df_eval = None # TODO: reset the index\n",
        "df_test = None # TODO: reset the index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_eval.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCpSVovObFrV"
      },
      "source": [
        "<h2 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "بررسی مجموعه‌داده\n",
        "</font>\n",
        "</h2>\n",
        "\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\">\n",
        "همچون تمام مسائل دیگر، بررسی و تحلیل داده‌ها از اهمیت بسیار زیادی برخوردار است. بنابراین ابتدا چند نمونه از تصاویر موجود در مجموعه‌داده را به‌صورت تصادفی انتخاب و ترسیم کنیم.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T12:06:17.119114Z",
          "iopub.status.busy": "2024-02-27T12:06:17.118514Z",
          "iopub.status.idle": "2024-02-27T12:06:18.541646Z",
          "shell.execute_reply": "2024-02-27T12:06:18.538709Z",
          "shell.execute_reply.started": "2024-02-27T12:06:17.119069Z"
        },
        "id": "UW4GFNP8bFrV",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "row, col = 3, 5\n",
        "img_size = 14\n",
        "fig, axes = plt.subplots(row, col, figsize=(img_size,img_size*row/col))\n",
        "fig.tight_layout()\n",
        "fig.subplots_adjust(hspace=.25)\n",
        "emotions = ['anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise', 'neutral']\n",
        "\n",
        "# Print row*col random images\n",
        "for i in range(row):\n",
        "    for j in range(col):\n",
        "        ax = axes[i,j]\n",
        "        k = np.random.randint(len(df_train.image)) # Pick a random image in the dataset\n",
        "        img = df_train.image[k].reshape(48,48)\n",
        "        lbl = emotions[df_train.emotion_idx[k]].capitalize() # Label for the image\n",
        "        ax.set_title(f'{lbl}')\n",
        "        ax.imshow(img, cmap='gray')\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNBZv0l6iPhk"
      },
      "source": [
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\">\n",
        "بسیار مهم است که در کنار به تصویر کشیدن داده‌ها، برچسب‌ها را هم بررسی کنیم. این کار را خودتان انجام داده و بررسی کنید که آیا همه‌ی برچسب‌ها (احساسات) به یک میزان در مجموعه‌ی آموزشی موجود هستند (مجموعه‌داده متوازن است)؟\n",
        "شایان ذکر است که\n",
        "این بخش از کد شما اختیاری بوده و نمره‌دهی نمی‌شود.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TG4qOllRiorI"
      },
      "outputs": [],
      "source": [
        "emotion_counts = None # TODO: use value_counts to count the number of each emotion in df_train\n",
        "\n",
        "# Create a dictionary to map emotion_idx to emotion_name\n",
        "emotion_map = {idx: name for idx, name in enumerate(emotions)}\n",
        "\n",
        "# Use the map to rename the index of emotion_counts\n",
        "emotion_counts = emotion_counts.rename(index=emotion_map)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.bar(emotion_counts.index, emotion_counts.values)\n",
        "plt.xlabel('Emotion')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of Emotions')\n",
        "\n",
        "# Set the x-axis labels\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocxnoap5jlId"
      },
      "source": [
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\">\n",
        "همچنین ما نیاز داریم که قبل از ورودی دادن تصاویر به مدل، مقادیر آن‌ها را نرمال کنیم.\n",
        "برای این کار نیاز داریم که میانگین (<code>mean</code>) و انحراف از معیار (<code>std</code>) مقادیر را بدانیم.\n",
        "این دو عدد را برای مجموعه‌ی آموزشی محاسبه کرده و حاصل را در متغیرهای مربوطه ذخیره کنید.\n",
        "<br>  \n",
        "در مورد انحراف از معیار می‌توانید در این <a href=\"https://en.wikipedia.org/wiki/Standard_deviation\">لینک</a>  بیشتر بخوانید.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T12:20:32.077397Z",
          "iopub.status.busy": "2024-02-27T12:20:32.077107Z",
          "iopub.status.idle": "2024-02-27T12:20:32.704946Z",
          "shell.execute_reply": "2024-02-27T12:20:32.704119Z",
          "shell.execute_reply.started": "2024-02-27T12:20:32.077366Z"
        },
        "id": "FcJuZELFbFrW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "mean = None # TODO\n",
        "std = None # TODO\n",
        "print(mean, std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od4ckcUqbFrW"
      },
      "source": [
        "<h2 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "ساخت <code>Dataset</code> در پای‌تورچ\n",
        "</font>\n",
        "</h2>\n",
        "\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\">\n",
        "برای ساخت یک بارگیرنده‌ی مجموعه‌داده در پای‌تورچ نیاز است یک کلاس (<code>class</code>) بسازیم که از کلاس <code>Dataset</code> ارث‌بری می‌کند. چیزی که مهم است این است که این کلاس باید شامل سه تابع <code>__init__</code>، <code>__len__</code> و <code>__get_item__</code> باشد.\n",
        "در ادامه در مورد نقش هر کدام توضیح می‌دهیم.\n",
        "<ul dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<li>\n",
        "<code>__init__(self, ...)</code>:\n",
        "در این تابع شما معمولاْ باید کار‌هایی را انجام دهید که فقط یک‌بار نیاز به اجرای آن‌ها دارید. این تابع در زمان تعریف کلاس صدا زده می‌شود.\n",
        "</li><li>\n",
        "<code>__len__(self)</code>:\n",
        "این تابع باید تعداد نمونه‌ها در مجموعه‌داده‌ی شما را برگرداند.\n",
        "</li><li>\n",
        "<code>__get_item__(self, idx)</code>:\n",
        "در این تابع که تابع اصلی این کلاس محسوب می‌شود، شما باید\n",
        "نمونه‌ای با نمایه‌ی <code>idx</code> را به همراه پاسخ/برچسب حقیقی آن برگردانید.\n",
        "مثلا در حالت ما <code>get_item(2)</code> باید عکس شماره‌ی <code>2</code> و <code>emotion_idx</code> مربوط به آن را برگرداند.\n",
        "</li>\n",
        "</ul>\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\">\n",
        "همچنین با استفاده از توابع موجود در ماژول <code>transforms</code> پای‌تورچ می‌توانید جهت پاکسازی، نرمال‌سازی و حتی تقویت داده‌ها بهره ببرید. در زیر به‌تعدادی از این توابع اشاره شده است.\n",
        "\n",
        "<ul dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<li>\n",
        "<code>transforms.Resize</code>:\n",
        " عکس ورودی را تغییر اندازه می‌دهد.\n",
        " </li><li>\n",
        "<code>transforms.ToTensor</code>:\n",
        "عکس ورودی را به یک آرایه‌ی عددی تبدیل می‌کند.\n",
        "</li><li>\n",
        "<code>transforms.Normalize</code>:\n",
        "با گرفتن میانگین و انحراف از معیار، تصویر ورودی را نرمال می‌کند.\n",
        "</li><li>\n",
        "<code>transforms.RandomRotation</code>:\n",
        "عکس را به‌صورت تصادفی با یک احتمال مشخص دوران می‌دهد. این موضوع باعث می‌شود که مدل برای آموزش خود تصاویر بیشتری در اختیار داشته باشد، چرا که می‌دانیم با چرخاندن یک عکس، برچسب آن تغییر نمی‌کند.\n",
        "با این حال باید توجه کنیم که این کار را فقط برای داده‌ی آموزشی انجام دهیم و بر روی داده‌ی آزمون تغییری ایجاد نکنیم.\n",
        "</li>\n",
        "<li>\n",
        "از <a href=\"https://pytorch.org/vision/0.15/transforms.html\">این لینک</a>  می‌توانید توابع بیشتری را شناخته و به کار بگیرید.\n",
        "\n",
        "</li>\n",
        "</ul>\n",
        "\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T12:32:14.671137Z",
          "iopub.status.busy": "2024-02-27T12:32:14.670563Z",
          "iopub.status.idle": "2024-02-27T12:32:14.681995Z",
          "shell.execute_reply": "2024-02-27T12:32:14.681134Z",
          "shell.execute_reply.started": "2024-02-27T12:32:14.671097Z"
        },
        "id": "kvOSXK-QbFrW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class ImgDataset(Dataset):\n",
        "    def __init__(self, df, train=False):\n",
        "        self.df = df\n",
        "        if train:\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.Resize((224, 224)),  # Resize the image to 224*224 (resnet18 input size)\n",
        "                transforms.RandomRotation(degrees=30), # Random rotation (only for trian) # add you own transforms\n",
        "                transforms.ToTensor(),  # Convert the PIL Image to tensor.\n",
        "                transforms.Normalize(mean=[mean], std=[std]),  # Normalize the tensor\n",
        "                transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  # Convert to 3 channels\n",
        "            ])\n",
        "        else:\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.Resize((224, 224)),  # Resize the image to 224*224 (resnet18 input size)\n",
        "                transforms.ToTensor(),  # Convert the PIL Image to tensor.\n",
        "                transforms.Normalize(mean=[mean], std=[std]),  # Normalize the tensor\n",
        "                transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  # Convert to 3 channels\n",
        "            ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.df.image[idx].reshape(48,48)\n",
        "        lbl = self.df.emotion_idx[idx] # Label is index (i.e. argmax of one-hot representation)\n",
        "        img = Image.fromarray(img) # Convert to PIL Image\n",
        "        img = self.transform(img)\n",
        "        sample = (img, lbl) # Sample is the pair (features, target)\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmeFKYZ1p2Hd"
      },
      "source": [
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\">\n",
        "باید ستون <code>emotion_idx</code> را به داده‌ی آزمون هم اضافه کنیم تا بتوانیم از کلاس نوشته‌شده بدون نیاز به تغییرات بیشتری استفاده کنیم. این ستون را اضافه کرده و مقدار لیبل‌ها را <code dir=ltr>-1</code> بگذارید.\n",
        "در نهایت با استفاده از کلاس نوشته شده مجموعه‌داده‌ها را بسازید.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T12:32:14.852696Z",
          "iopub.status.busy": "2024-02-27T12:32:14.852465Z",
          "iopub.status.idle": "2024-02-27T12:32:14.858848Z",
          "shell.execute_reply": "2024-02-27T12:32:14.858020Z",
          "shell.execute_reply.started": "2024-02-27T12:32:14.852670Z"
        },
        "id": "cT8_B_uAbFrW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_dataset = ImgDataset(df_train, train=True)\n",
        "eval_dataset = None # TODO\n",
        "\n",
        "# TODO ( add 'emotion_idx' to df_test)\n",
        "test_dataset =  None # TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6DjmfGjqb1N"
      },
      "source": [
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\">\n",
        "همان‌طور که در درسنامه‌های این فصل خواندید پای‌تورچ از مفهوم <code>DataLoader</code> هم استفاده می‌کند. با استفاده از کلاس <code>DataLoader</code> سه بارگیرنده‌ی داده می‌سازیم که داده‌ها را با <code>batch_size</code> ای که مشخص می‌کنیم آماده می‌کند.\n",
        "<br>\n",
        "برای <code>DataLoader</code> مجموعه‌ی آموزشی خیلی خوب است که <code>shuffle=True</code> را هم تنظیم کنیم تا در دورهای های مختلف، داده‌ها با ترتیب‌های متفاوتی توسط مدل دیده شوند و نمونه‌های کلاس‌های مختلف با هم بُر بخورند.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_4d58j3qakr"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "eval_dataloader =  DataLoader(eval_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
        "test_dataloader =  DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBacOXvTbFrW"
      },
      "source": [
        "<h2 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "تعریف مدل در پای‌تورچ\n",
        "</font>\n",
        "</h2>\n",
        "\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\">\n",
        "مشابه ساخت مجموعه‌داده در پای‌تورچ مدل‌ها هم ‌به‌شکل یک کلاس طراحی می‌شوند که باید از کلاس\n",
        "<code>torch.nn.Module</code>\n",
        "ارث‌بری کنند. در این کلاس شما باید دو تابع مهم\n",
        "<br>\n",
        "<code>__init__</code> و <code>forward</code> را پیاده‌سازی کنید تا پای‌تورچ  با استفاده از این‌ دو تابع مدل را ساخته و از آن استفاده کند. در ادامه نقش هر کدام از این توابع را شرح می‌دهیم.\n",
        "<ul dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<li>\n",
        "<code>init(self, ...)</code>:\n",
        "در این تابع شما معمولاً باید کار‌هایی را انجام دهید که فقط یک‌بار نیاز به انجام آن‌ها دارید. این تابع در زمان ساخت شبکه صدا زده می‌شود. در این تابع شما باید لایه‌های مدل را تعریف کنید.\n",
        "</li><li>\n",
        "<code>forward(self, x)</code>:\n",
        "در این تابع که تابع اصلی یک مدل محسوب می‌شود، شما باید با گرفتن ورودی (<code>x</code>) خروجی شبکه را محاسبه کرده و خروجی دهید.\n",
        "این ورودی یک تنسور است که شامل تعدادی نمونه می‌شود. تعداد نمونه‌ها برابر با بعد اول تنسور ورودی است. مثلاً در سوال ما تنسور ورودی ابعاد زیر را دارد.\n",
        "<br>\n",
        "<code>[batch_size, 3, 224, 224] </code>\n",
        "</li>\n",
        "</ul>\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\">\n",
        "برای طراحی شبکه‌ی خود می‌خواهیم از معماری معروف <code>resnet18</code> و با وزن‌های پیش‌آموخته استفاده کنیم. برای این کار می‌توانید از تابع <code>torchvision.models.resnet18(pretrained=True)</code> استفاده کنید. سپس لایه‌ی آخر آن را حذف کرده و دو لایه‌ی خطی به‌ترتیب با تابع فعال‌ساز <code>ReLU</code> و <code>Softmax</code> اضافه کنید. برای آشنایی با نحوه‌ی پیاده‌سازی تابع فعال‌ساز <code>ReLU</code> و <code>Softmax</code> می‌توانید به <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html\">این لینک</a> و <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html\">این لینک</a> مراجعه کنید.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T12:32:15.128073Z",
          "iopub.status.busy": "2024-02-27T12:32:15.127840Z",
          "iopub.status.idle": "2024-02-27T12:32:15.137092Z",
          "shell.execute_reply": "2024-02-27T12:32:15.136354Z",
          "shell.execute_reply.started": "2024-02-27T12:32:15.128047Z"
        },
        "id": "sX-6aej6bFrX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Emotional_resnet18(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Emotional_resnet18, self).__init__()\n",
        "        # Load a pre-trained ResNet18 model\n",
        "        resnet18 = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "        self.backbone = torch.nn.Sequential(*list(resnet18.children())[:-1])\n",
        "        self.l1 = nn.Linear(512, 100)\n",
        "        self.l2 = nn.Linear(100, 7)\n",
        "\n",
        "        self.relu = None # TODO\n",
        "        self.softmax = None # TODO\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x).reshape(-1,512)\n",
        "        x = None # TODO: pass x through l1\n",
        "        x = None # TODO: pass x through relu\n",
        "        x = None # TODO: pass x through l2\n",
        "        x = None # TODO: pass x through softmax\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoDuMCK8bFrX"
      },
      "source": [
        "<h2 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "آموزش مدل\n",
        "</font>\n",
        "</h2>\n",
        "\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\">\n",
        "ابتدا می‌خواهیم بررسی کنیم که سیستمی که برای آموزش مدل استفاده می‌کنیم دارای <i>GPU</i> است یا خیر. برای این کار می‌توانید از تابع <code>torch.cuda.is_available()</code> استفاده کنید. اگر چنین بود طبیعتاْ بهتر است که از <i>GPU</i> برای آموزش مدل استفاده کنیم. توجه داشته باشید که پیشنهاد ما استفاده از محیط گوگل کولب (یا نت‌بوک کگل) جهت آموزش مدل است، زیرا که به‌صورت رایگان امکان استفاده از <i>GPU</i> را فراهم می‌کنند.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T12:32:15.828647Z",
          "iopub.status.busy": "2024-02-27T12:32:15.828023Z",
          "iopub.status.idle": "2024-02-27T12:32:15.833468Z",
          "shell.execute_reply": "2024-02-27T12:32:15.832684Z",
          "shell.execute_reply.started": "2024-02-27T12:32:15.828614Z"
        },
        "id": "FQlvE25gbFrX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Select GPU if available\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR32cKaJ7REe"
      },
      "source": [
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\">\n",
        "فرایند یادگیری مدل در پای‌تورچ شامل مراحل زیر است.\n",
        "\n",
        "<ol dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<li>\n",
        "گرفتن نمونه‌ها از <code>DataLoader</code>\n",
        "</li><li>\n",
        "انتقال نمونه‌ها به <i>GPU</i>\n",
        "</li><li>\n",
        "ورودی دادن نمونه‌ها به مدل و محاسبه‌ی خروجی مدل\n",
        "</li><li>\n",
        "محاسبه‌ی زیان (loss) بر روی این نمونه‌ها\n",
        "</li><li>\n",
        "محاسبه‌ی مشتق وزن‌ها نسبت به زیان با استفاده از <code>loss.backward</code>\n",
        "</li><li>\n",
        "به‌روزرسانی وزن‌های شبکه با استفاده از <code>optimizer.step</code>\n",
        "</li><li>\n",
        "پاک کردن مشتق‌ها از روی وزن‌ها (صفر کردن آن‌ها) با استفاده از <code>optimizer.zero_grad</code>\n",
        "</li>\n",
        "</ol>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "در شرایطی که بخواهیم از مدل برای نمونه‌های اعتبارسنجی/آزمون استفاده کنیم (به‌اصطلاح مدل را در حالت تست قرار دهیم) و نخواهیم فرآیند یادگیری را روی آن انجام دهیم می‌توانیم بیشتر این مراحل را حذف کرده و نهایتاْ به مراحل زیر برسیم.\n",
        "\n",
        "<ol dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<li>\n",
        "گرفتن نمونه‌ها از <code>DataLoader</code>\n",
        "</li><li>\n",
        "انتقال نمونه‌ها به <i>GPU</i>\n",
        "</li><li>\n",
        "ورودی دادن نمونه‌ها به مدل و محاسبه‌ی خروجی مدل\n",
        "</li><li>\n",
        "محاسبه‌ی زیان (loss) بر روی این نمونه‌ها (در صورتی‌که مقدار زیان برای‌مان اهمیت داشته باشد)\n",
        "</li><li>\n",
        "محاسبه‌ی برچسبی که بیشترین احتمال را دارد.\n",
        "</li><li>\n",
        "محاسبه‌ی دقت مدل بر روی این دسته از نمونه‌ها\n",
        "</li>\n",
        "</ol>\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<span style=\"color:orange\"><b>نکته‌ی ۱:</b></span>\n",
        "همچنین نیاز است زمانی‌که یک مدل را آموزش می‌دهیم قبل از شروع آموزش آن، <code>()model.train</code> را صدا بزنیم و زمانی‌که می‌خواهیم مدل را آزمایش کنیم <code>()model.eval</code> را صدا بزنیم.\n",
        "<br>\n",
        "<span style=\"color:orange\"><b>نکته‌ی ۲:</b></span>\n",
        "هنگامی‌که قرار نیست مشتق‌گیری کنیم (مثلاً در زمان آزمون) می‌توانیم کد را درون <code>()with torch.no_grad</code> قرار دهیم. این کار باعث می‌شود که حافظه‌ی کمتری مصرف شود و محاسبات سریع‌تر باشد چرا که پای‌تورچ دیگر آماده‌ی محاسبه کردن مشتق‌ها نیست و نحوه‌ی محاسبه کردن اعداد را پاک می‌کند، یعنی اطلاعاتی که برای محاسبه‌ی مشتق حیاتی هستند. این نگه نداشتن اطلاعات مربوط به نحوه‌ی محاسبه‌ باعث افزایش چشمگیر سرعت خواهد شد.\n",
        "\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T13:16:28.965121Z",
          "iopub.status.busy": "2024-02-27T13:16:28.964824Z",
          "iopub.status.idle": "2024-02-27T13:18:00.532658Z",
          "shell.execute_reply": "2024-02-27T13:18:00.531669Z",
          "shell.execute_reply.started": "2024-02-27T13:16:28.965080Z"
        },
        "id": "EWu8AAw3bFrY",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from sklearn.metrics import *\n",
        "from tqdm import tqdm\n",
        "\n",
        "net = Emotional_resnet18().to(device)\n",
        "loss_func = nn.CrossEntropyLoss() # Because of multiclass classification task\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-4) # State-of-the-art optimizer\n",
        "\n",
        "epochs = 30\n",
        "\n",
        "def learn_one_step(net, optimizer, data, device, loss_func):\n",
        "    inputs, labels =  None # TODO: step 1: get the data from the data tuple\n",
        "    inputs = None # TODO: step 2: move the inputs to the device\n",
        "    labels = None # TODO: step 2: move the labels to the device\n",
        "\n",
        "    outputs = None # TODO: step 3: forward pass (pass the inputs.float() through the net)\n",
        "    loss =  None # TODO: step 4: compute the loss by passing the outputs and labels through the loss_func\n",
        "    # step 5: compute the gradient using loss.backward()\n",
        "    # step 6: update the weights using optimizer.step()\n",
        "    # step 7: reset the gradients using optimizer.zero_grad()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "def evaluate_one_step(net, data,  device, loss_func):\n",
        "    with torch.no_grad():\n",
        "        inputs, labels =  None # TODO: step 1: get the data from the data tuple\n",
        "        inputs = None # TODO: step 2: move the inputs to the device\n",
        "        labels = None # TODO: step 2: move the labels to the device\n",
        "\n",
        "        outputs =  None # TODO: step 3: forward pass (pass the inputs.float() through the net)\n",
        "        loss = None # TODO: step 4: compute the loss by passing the outputs and labels through the loss_func\n",
        "        outputs_idx = None # TODO: step 5: get the index of the maximum value in the outputs\n",
        "        accuracy= None # TODO: step 6: compute the accuracy using the outputs_idx and labels\n",
        "\n",
        "        return accuracy.item(), loss.item()\n",
        "\n",
        "history_loss=[]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f'Epoch {epoch+1}')\n",
        "    running_loss = 0\n",
        "\n",
        "    # Training\n",
        "    net.train()\n",
        "    for i, data in enumerate(tqdm(train_dataloader)):\n",
        "\n",
        "        loss = learn_one_step(net, optimizer, data, device, loss_func)\n",
        "\n",
        "        # monitoring training loss\n",
        "        running_loss += loss\n",
        "        if i % 100 == 99:\n",
        "            history_loss.append(running_loss/100)\n",
        "            print('loss: %.3f' % (running_loss / 100))\n",
        "            running_loss = 0\n",
        "\n",
        "\n",
        "    # Validation (performed on test set)\n",
        "    batch_accuracies, batch_losses=[], []\n",
        "    net.eval()\n",
        "    for i, data in enumerate(eval_dataloader, 0):\n",
        "        batch_accuracy, batch_loss = evaluate_one_step(net, data, device, loss_func)\n",
        "\n",
        "        batch_accuracies.append(batch_accuracy)\n",
        "        batch_losses.append(batch_loss)\n",
        "\n",
        "    acc = torch.mean(torch.tensor(batch_accuracies))*100\n",
        "    loss = torch.mean(torch.tensor(batch_losses))\n",
        "    print('Validation accuracy: {acc:.2f}%, Validation loss: {loss:.4f}'.format(acc=acc, loss=loss))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOplwmgUm4fr"
      },
      "source": [
        "<h2 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "آزمایش مدل و تولید پیش‌بینی\n",
        "</font>\n",
        "</h2>\n",
        "\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "برای ارزیابی مدل خود از ماتریس درهم‌ریختگی (confusion matrix) استفاده می‌کنیم. در این ماتریس می‌توان دید که نمونه‌های مربوط هر احساس به چه‌نحوی توسط مدل تشخیص داده شده‌اند. مثلاً آیا بیشتر نمونه‌های با احساس خوشحالی توسط مدل به دسته‌ی ناراحتی اختصاص داده می‌شوند و یا خشم؟\n",
        "<br>\n",
        "برای محاسبه‌ی این ماتریس از تابع <code>ConfusionMatrixDisplay</code> (<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html\">مطالعه‌ی مستندات</a>) استفاده می‌کنیم. به این تابع باید دو آرایه ورودی دهیم که شامل برچسب‌های اصلی و پیش‌بینی مدل است. این کار را برای نمونه‌های اعتبارسنجی انجام داده و عملکرد مدل را ارزیابی کنید.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-12-12T21:09:49.761797Z",
          "iopub.status.busy": "2021-12-12T21:09:49.76127Z",
          "iopub.status.idle": "2021-12-12T21:09:50.725714Z",
          "shell.execute_reply": "2021-12-12T21:09:50.724923Z",
          "shell.execute_reply.started": "2021-12-12T21:09:49.761754Z"
        },
        "id": "G8Sfzob5bFrZ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_model_predictions(net, data,  device):\n",
        "    with torch.no_grad():\n",
        "        inputs, labels = None # TODO: step 1: get the data from the data tuple\n",
        "        inputs =  None # TODO: step 2: move the inputs to the device\n",
        "        labels =  None # TODO: step 2: move the labels to the device\n",
        "\n",
        "        outputs = None # TODO: step 3: forward pass (pass the inputs.float() through the net)\n",
        "        outputs_idx =  None # TODO: step 4: get the index of the maximum value in the outputs\n",
        "        return outputs_idx.cpu().tolist()\n",
        "\n",
        "net.eval()\n",
        "eval_outputs=[]\n",
        "eval_labels=[]\n",
        "for i, data in enumerate(eval_dataloader, 0):\n",
        "    outputs_idx = get_model_predictions(net, data,  device)\n",
        "\n",
        "    eval_outputs+=outputs_idx\n",
        "    eval_labels+=data[1].tolist()\n",
        "\n",
        "ConfusionMatrixDisplay(confusion_matrix(eval_labels, eval_outputs), display_labels=['anger', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']).plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niXO-tSisVq0"
      },
      "source": [
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "حال برای این که عملکرد مدل را روی تعدادی نمونه ببینیم، تعدادی از تصاویر مجموعه‌ی اعتبارسنجی (evaluation) را به همراه پیش‌بینی مدل به تصویر می‌کشیم."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T13:30:19.867960Z",
          "iopub.status.busy": "2024-02-27T13:30:19.867655Z",
          "iopub.status.idle": "2024-02-27T13:30:21.316901Z",
          "shell.execute_reply": "2024-02-27T13:30:21.316162Z",
          "shell.execute_reply.started": "2024-02-27T13:30:19.867925Z"
        },
        "id": "4zaYGzLwbFra",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# visualize better what we are working with\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "row, col = 2, 5\n",
        "img_size = 14 # Size of each picture in the plot\n",
        "fig, axes = plt.subplots(row, col, figsize=(img_size,img_size*row/col))\n",
        "fig.tight_layout()\n",
        "fig.subplots_adjust(hspace=.25)\n",
        "\n",
        "# Print row*col random images\n",
        "for i in range(row):\n",
        "    for j in range(col):\n",
        "        ax = axes[i,j]\n",
        "        k = np.random.randint(len(df_eval.image)) # Pick a random image in the dataset\n",
        "        img = df_eval.image[k].reshape(48,48)\n",
        "        output = emotions[eval_outputs[k]].capitalize()# prediction for the image\n",
        "        label = emotions[eval_labels[k]].capitalize()# label for the image\n",
        "        ax.set_title(f'pred:{output}, label:{label}')\n",
        "        ax.imshow(img, cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWoFvOq-xQOP"
      },
      "source": [
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "نظرتان در مورد پیشبینی‌های مدل چیست؟ با نظر مدل‌تان بیشتر موافق هستید یا برچسب‌های اصلی مجموعه‌داده؟"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<h3 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "معیار ارزیابی\n",
        "</font>\n",
        "</h3>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "برای ارزیابی عملکرد مدل شما بر روی نمونه‌های آزمون از معیار <code>Accuracy</code> استفاده می‌کنیم. این معیار نسبت تعداد پیش‌بینی‌های صحیح مدل به کل نمونه‌های آزمون را نشان می‌دهد. از مدل خود جهت تولید پیش‌بینی احساس نمونه‌های آزمون استفاده کرده و نتایج را در <code>test_prediction</code> ذخیره می‌کنیم.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font color=\"red\"><b color='red'>توجه:</b></font>\n",
        "<font face=\"vazir\" size=3>\n",
        " جهت کسب امتیاز کامل نیاز است تا پاسخ شما حداقل امتیاز <code>63</code> را با توجه به معیار معرفی‌شده کسب نماید.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font color=\"orange\"><b color='red'>نکته:</b></font>\n",
        "<font face=\"vazir\" size=3>\n",
        "توجه داشته باشید که در این تمرین علاوه بر دقت مدل شما بر روی نمونه‌های آزمون، میانگین و انحراف معیار محاسبه‌شده نیز مورد بررسی قرار خواهد گرفت.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSJY-rQQwtSw"
      },
      "outputs": [],
      "source": [
        "net.eval()\n",
        "test_prediction = []\n",
        "for i, data in enumerate(test_dataloader, 0):\n",
        "    outputs_idx = get_model_predictions(net, data,  device)\n",
        "    test_prediction += outputs_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEoz3V9LyX8t"
      },
      "source": [
        "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "<b>سلول جواب‌ساز</b>\n",
        "</font>\n",
        "</h2>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "    برای ساخته‌شدن فایل <code>result.zip</code> سلول زیر را اجرا کنید. توجه داشته باشید که پیش از اجرای سلول زیر تغییرات اعمال شده در نت‌بوک را ذخیره کرده باشید (<code>ctrl+s</code>) تا در صورت نیاز به پشتیبانی امکان بررسی کد شما وجود داشته باشد. همچنین اگر از گوگل کولب استفاده می‌کنید، در صورت نیاز به پشتیبانی حتماً آخرین نسخه از نت‌بوک را به‌صورت دستی دانلود کرده و داخل فایل ارسالی قرار دهید یا لینک کولب را با ما به‌اشتراک بگذارید.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSGszin5yXdz"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import joblib\n",
        "import numpy as np\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "with open('mean_std.pkl', 'wb') as f:\n",
        "    pickle.dump({\"mean\":mean, \"std\":std}, f)\n",
        "\n",
        "np.save(\"test_prediction\", np.array(test_prediction))\n",
        "\n",
        "if not os.path.exists(os.path.join(os.getcwd(), 'emotion.ipynb')):\n",
        "    %notebook -e emotion.ipynb\n",
        "\n",
        "def compress(file_names):\n",
        "    print(\"File Paths:\")\n",
        "    print(file_names)\n",
        "    compression = zipfile.ZIP_DEFLATED\n",
        "    with zipfile.ZipFile(\"result.zip\", mode=\"w\") as zf:\n",
        "        for file_name in file_names:\n",
        "            zf.write('./' + file_name, file_name, compress_type=compression)\n",
        "\n",
        "file_names = ['mean_std.pkl', 'test_prediction.npy', 'emotion.ipynb']\n",
        "compress(file_names)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 4503377,
          "sourceId": 7711992,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30153,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
